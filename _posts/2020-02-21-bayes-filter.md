---
layout: article
title:  'Bayes Filter!'
tags: SLAM BayesFilter DBN HMM
aside:
  toc: true
mathjax: true
mathjax_autoNumber: true
cover: /image/posts/2020-02-21/1.bayes_filter.png
---

![bayes_filter](/image/posts/2020-02-21/1.bayes_filter.png)

解决机器人SLAM问题有两大算法家族————贝叶斯滤波器和图优化，本文将系统地介绍贝叶斯滤波器的原理，并介绍由贝叶斯滤波器衍生出的一系列算法。

<!--more-->

## 1. 贝叶斯法则

介绍贝叶斯法则要从条件概率说起，我们用$p(X=x)$表示事件$X$中$x$发生的概率，举例来说：抛一枚硬币是事件$X$，正面朝上$x$是其中一种结果，$x$发生的概率表示为$p(X=x)$，简写为$p(x)$。

<font color="#FF0000">条件概率</font>就是事件X在另一个事件Y已经发生的条件下的概率。同样举例来说：我抛一次硬币为事件Y，正面朝上用$y$表示，那么$Y=y$，我再抛一次硬币为事件X，正面朝上用$x$表示，那么第二次还是正面朝上的概率为$p(X=x)$，在第一次抛硬币正面朝上的基础上第二次抛硬币正面朝上的条件概率就是$p(X=x|Y=y)$，简写为$p(x|y)$。

<font color="#FF0000">贝叶斯准则</font>公式如下：

$$p(x|y) = \frac{p(y|x)p(x)}{p(y)}$$

当然，以上等式要求$p(y) \neq 0$。我们把上面公式两边同时乘以$p(y)$，可以得到：

$$p(x|y) * p(y) = p(y|x) * p(x)$$

公式左边表示：在$y$发生的情况下$x$也发生的概率$p(x|y)$ __乘以__ $y$ 发生的概率$p(y)$，结果很简单，就是$x$和$y$同时发生了，这个同时发生的概率我们用$p(x,y)$表示；等式右边结果一样，也等于$p(x, y)$，贝叶斯法则就这样证明完成。

我们再把上面的准则扩展到三个事件，得到我们贝叶斯滤波器要用到的最终的贝叶斯法则(证明省略)：

$$p(x|y,z) = \frac{p(y|x,z)p(x|z)}{p(y|z)}$$


## 2.动态贝叶斯网络

正如本文最上面的图片所展示的那样，我们可以将机器人SLAM问题表示为一个由控制$u$和测量$z$推算机器人状态$x$的过程。

控制量我们用$u$表示，$u_t$表示$t$时刻的控制量，$u_{1:t}$表示从时间$t_1$到时间$t_t$这段时间内所有的控制量；测量值我们用$z$表示，同样的$z_{1:t}$表示这段时间内的所有测量值。

我们最终的目标是：在已知所有的控制量和测量值的情况下推算出当前时刻机器人的状态，用公式表示这个条件概率为：

$$p(x_t|u_{1:t},z_{1:t})$$

我们将它用贝叶斯准则展开(用$x_t$替换$x$、$y$替换$z_t$，$z$替换$z_{1:t-1},u_{1:t}$)：


$$\begin{aligned}
p(x_t|u_{1:t},z_{1:t})  &= p(x_t|u_{1:t},z_{1:t-1},z_t) \\ \\ &= \frac{p(z_t|x_t,z_{1:t-1},u_{1:t})p(x_t|z_{1:t-1},u_{1:t})}{p(z_t|z_{1:t-1},u_{1:t})}  
\end{aligned}$$

因为$p(z_t|z_{1:t-1},u_{1:t})$中没有任何变量与$x$有关，每个可能的状态的条件概率都包含同样分母，所以我们可以直接用常量$\eta$代替它，由此我们得到了以下等式：

$$
p(x_t|u_{1:t},z_{1:t})  = \eta p(z_t|x_t,z_{1:t-1},u_{1:t})p(x_t|z_{1:t-1},u_{1:t})
$$

所以问题就转化为求解$p(z_t|x_t,z_{1:t-1},u_{1:t})$和$p(x_t|z_{1:t-1},u_{1:t})$。

$p(z_t|x_t,z_{1:t-1},u_{1:t})$的物理意义是：已知$x_t$（t时刻机器人状态）、$z_{1:t-1}$（1到t-1时刻所有的测量值）、$u_{1:t}$（1到t时刻所有的控制量）的情况下$z_t$发生的概率。

$p(x_t|z_{1:t-1},u_{1:t})$的物理意义是：已知$z_{1:t-1}$（1到t-1时刻所有的测量值）、$u_{1:t}$（1到t时刻所有的控制量）的情况下$x_t$发生的概率。

此时，为了简化我们的计算，引入马尔可夫假设，也叫作完整状态假设：假设状态能够完全代表过去所有的变量，换句话说就是当前状态已知的情况下，以后的状态与之前的数据相互独立（不相关），用公式表示就是$p(x_t | u_{1:t},z_{1:t}) = p(x_t|x_{t-1}, u_t, z_t)$，即在我们求解的问题中，如果已经知道了$x_{t-1}$，则不再需要以前的控制量和测量值。

在马尔可夫假设的前提下，我们可以将以上的两个公式分别简化为：

$$p(z_t|x_t,z_{1:t-1},u_{1:t}) = p(z_t|x_t)$$

$$\begin{aligned}
p(x_t|z_{1:t-1},u_{1:t}) &= \int p(x_t|x_{t-1},z_{1:t-1},u_{1:t})p(x_{t−1}|z_{1:t−1},u_{1:t})dx_{t-1} \\ &= \int p(x_t|x_{t-1},u_t)p(x_{t-1}|z_{1:t-1},u_{1:t-1})dx_{t-1}\end{aligned}$$

上面的推导过程中，引入了全概率公式：$p(x) =\int p(x|y)p(y) dy$，离散的全概率公式为：$p(x)=\sum_y p(x|y)p(y)$。另外，$p(x_{t−1}|z_{1:t−1},u_{1:t})$可以转化为$p(x_{t-1}|z_{1:t-1},u_{1:t-1})$是因为$p(x_{t-1})$与$u_t$没有任务关系，所以可以直接去除。

综上，我们可以得到以下公式：


$$p(x_t|u_{1:t},z_{1:t}) = \eta p(z_t|x_t) \int p(x_t|x_{t-1},u_t)p(x_{t-1}|z_{1:t-1},u_{1:t-1})dx_{t-1}$$

从公式我们可以看出，$x_t$的条件概率分布可以由两步计算得到：
- $p(x_t|x_{t-1},u_t)p(x_{t-1}|z_{1:t-1},u_{1:t-1})$: 由$x_{t-1}$和$u_t$得到$x_t$，此处的$x_t$仅仅是通过控制量估计$x_t$的值。
- $p(z_t|x_t)$: “由$x_t$得到$z_t$”，由于我们的目标是$x_t$，而$z_t$在实际计算过程中也是能够直接得到的，所以此处的“由$x_t$得到$z_t$”其实是通过计算$z_t$的概率来较正上一步得到$x_t$。

<font color="#f00">以上两步也可以被称为预测过程和更新（较正）过程，第一步是根据控制量预测，第二部是根据测量值较正，其实也就是将控制量和测量值进行了融合，得到了一个最佳的状态估计。</font>

我们将以上的这个过程表示为图的形式，即为：
![bayes_filter](/image/posts/2020-02-21/1.bayes_filter.png)

其中，实心圆表示可以直接得到的数据，空心圆表示需要求解的值。

该图即为<font color="#f00">动态贝叶斯网络（Dynamic Bayes Network, DBN）</font>，也被称为<font color="#f00">隐马尔可夫模型(Hidden Markov Model, HMM)</font>。


## 3.贝叶斯滤波器

根据以上的推算，我们可以轻松得到贝叶斯滤波器的完整算法：

连续形式为：
__BayesFilterContinuous(__ $bel(x_{t-1})$, $u_t$, $z_t$ __):__
&emsp; *for all $x_t$ do:*
&emsp;&emsp;  $\overline{bel}(x_t)$ = $\int p(x_t | u_t, x_{t−1}) bel(x_{t−1}) dx_{t−1}$
&emsp;&emsp;  $bel(x_t)$ = $\eta p(z_t|x_t) \overline{bel}(x_t)$
&emsp; *endfor*
&emsp; *return $bel(x_t)$*



离散形式为：
__BayesFilterDiscrete(__ $\{p_{k,t-1}\}$, $u_t$, $z_t$ __):__
&emsp; *for all $k$ do:*
&emsp;&emsp;  $\overline{p}_{k,t} = \sum_i p(X_t=x_k | u_t, X_{t-1} = x_i)p_{i,t−1}$
&emsp;&emsp;  $p_{k,t} = \eta p(z_t|X_t=x_k) \overline{p}_{k,t}$
&emsp; *endfor*
&emsp; *return* \{$p_{k,t}$\}


## 4. 算法家族

实际使用贝叶斯滤波器时，需要对状态的联合概率分布进行积分，计算量相当大，为了简化计算，通常会对概率分布进行近似，从而衍化出了各种贝叶斯滤波器的变化版本，不同的版本适合不同的问题，计算复杂度、对结果的影响也各不相同，大致的算法家族如下所示：

![bf_family](/image/posts/2020-02-21/2.bf_family.png)

这些算法在后续的博客中会详细介绍、实现。


---


