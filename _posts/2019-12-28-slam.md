---
layout: article
title:  'SLAM!'
tags: SLAM
aside:
  toc: true
mathjax: true
cover: /image/posts/2019-12-29/0.architecture.png
---

![architecture-all](/image/posts/2019-12-29/0.architecture-all.png)

最近看了杨亮的课程视频，了解了SLAM涉及到的研究领域，包括基本理论、传感器、地图、位姿估计与融合、回路和图优化以及深度学习相关六大领域。

<!--more-->

SLAM(Simultaneous Localization And Mapping)于1986年由Peter Cheeseman, Jim Crowley和Hugh Durrant Whyte等人提出。在此之前，机器人的位置都是通过积分的方式来计算，随着时间的推移，累积误差会越来越大。在此之后，SLAM经历过三大里程碑式的发展：
- EKF：扩展卡尔曼滤波，在卡尔曼滤波的基础上，通过贝叶斯概率持续矫正机器人位姿。
- Fast-SLAM：使用粒子滤波算法，用概率统计的方法解决了KF假设噪声满足高斯分布的限制。
- Graph-SLAM：使用图优化方法进行定位。

目前定位使用的传感器主要分为视觉和激光两类：
- 视觉：最早使用视觉进行SLAM的是Javier Civera, Andrew J. Davision，当时使用的是EKF方法；后续Georg Klein, David Murray使用多线程图优化进行SLAM，主要项目是PTAM-SLAM（Parallel Tracking And Mapping），后续还出现了RGBD-SLAM、ORB-SLAM、LSD-SLAM等。
- 激光：早期是GMapping、SLAM6D等方法；后续Ji Zhang的LOAM、V-LOAM加入了特征提取进行SLAM；Google开源了Cartographer项目进行激光SLAM。

### 一、基本理论

![base-theory](/image/posts/2019-12-29/1.base-theory.png)


#### 1. 数学表示

##### 1）机器人位姿的表示：

在三维空间中，欧式坐标系使用P和R分别表示位置和朝向：

$$P(x,y,z)$$

$$R(\alpha,\beta,\gamma)$$

但是这样表示在后续的计算中不方便<span style="color:red;">（原因后续更新）</span>，所以在三维空间中一般使用四元数
$$q=a+bi+cj+dk$$
表示。

##### 2） 卡尔曼滤波（Kalman Filter）

卡尔曼滤波器又被称作传感器融合算法（Sensor Fusion Algorithm），它的原理就是将多个传感器的预测结果或者测量结果进行融合，得到最佳的结果，从而减少误差。其推算过程如下：

为了推算方便，我们先用一维状态进行推算，假设我们有两个传感器（里程计和激光）同时对一辆小车的前进距离$x$进行估计。两个传感器肯定都是有误差的，我们假设预测的结果分别服从高斯分布$N(u_1, \sigma_1)$和$N(u_2, \sigma_2)$ ：

$$f(x)=\frac{1}{\sqrt{2π}\sigma_1}e^{\frac{-(x-u_1)^2}{2\sigma_1^2}} $$

$$g(x)=\frac{1}{\sqrt{2π}\sigma_2}e^{\frac{-(x-u_2)^2}{2\sigma_2^2}} $$

即：
- 里程计预测的结果是小车前进的距离期望是$u_1$，方差为$\sigma_1^2$
- 激光预测的结果是小车前进的距离期望是$u_2$，方差为$\sigma_2^2$

这两个传感器的预测是相互独立的，两个事件的最优估计的概率分布为：

$$f(x)*g(x)=\frac{1}{\sqrt{2π}\sigma_1}e^{\frac{-(x-u_1)^2}{2\sigma_1^2}} * \frac{1}{\sqrt{2π}\sigma_2}e^{\frac{-(x-u_2)^2}{2\sigma_2^2}} $$

计算后可以得到：
$$f(x)*g(x)=\frac{S_f}{\sqrt{2π}\sigma_f}e^{\frac{-(x-u_f)^2}{2\sigma_f^2}} $$

其中：

$$\sigma_f^2=\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2} $$

$$u_f=\frac{u_1\sigma_2^2+u_2\sigma_1^2}{\sigma_1^2+\sigma_2^2} $$

$$S_f=\frac{1}{\sqrt{2π(\sigma_1^2+\sigma_2^2)}}e^{\frac{-(u_1-u_2)^2}{2(\sigma_1^2+\sigma_2^2)}} $$

由此可以看出，两个高斯分布相乘后的结果还是一个高斯分布。由于$u_1, u_2, \sigma_1, \sigma_2 $都是固定值，因此$S_f$只是一个常数。

该过程即为两个传感器的估计结果融合的过程，融合后的结果为$N(u_f, \sigma_f)$，即两个传感器的结果融合后得到的最佳估计为$u_f$，最佳估计的方差为$\sigma_f^2$。

现在将$u_f$和$\sigma_f$进行变形，如下所示：

$$u_f=u_1 + \frac{\sigma_1^2(u_2-u_1)}{\sigma_1^2+\sigma_2^2}= u_1 + K*(u_2-u_1)$$

$$\sigma_f^2=\sigma_1^2-\frac{\sigma_1^4}{\sigma_1^2+\sigma_2^2}=\sigma_1^2-K*\sigma_1^2 $$

公式的物理意义即$u_f$的值等于传感器1的预测结果加上$K*(u_2-u_1)$，假设传感器1（即里程计）的估计误差比较大，即方差比较大，$\sigma_1^2$比较大，那么$K$值就越大，最终$u_f$的结果就越偏向于$u_2$的值，假设$\sigma_1^2$趋近于无穷大，那么K就无限趋近于1，那么$u_f=u_2$，由此可见，如果$u_1$误差越大，$u_f$的结果中$u_1$所占的权重就越小；反之，如果$\sigma_2$越大，则$K$越趋近于0，$u_f$越趋近于$u_1$。这就是卡尔曼滤波器被称为传感器融合算法的原因，其中K就是最重要的用于调节两个传感器结果的系数。

下面我们从融合的结果推算卡尔曼滤波的五个公式：

我们已经得到了以下三个公式：

$$u_f = u_1 + K*(u_2-u_1)$$

$$\sigma_f^2 = \sigma_1^2-K*\sigma_1^2$$

$$ K = \frac{\sigma_1^2}{\sigma_1^2+\sigma_2^2} $$

---

未完待续

<!-- 已知，$u_1$是根据里程计数据对前进距离的预测结果，



### 二、传感器

![sensor](/image/posts/2019-12-29/2.sensor.png)


### 三、地图

![map](/image/posts/2019-12-29/3.map.png)


### 四、位姿估计与融合

![pose](/image/posts/2019-12-29/4.pose.png)


### 五、回路和图优化

![g2o](/image/posts/2019-12-29/5.g2o.png)


### 六、深度学习

![deep-learning](/image/posts/2019-12-29/6.deep-learning.png)



 -->
